% vim: set spelllang=fr,en foldmethod=marker:
\section{Résolution des jeux}
\label{tj:sec:algo}

Cette section s'intéresse au problème posé par la résolution de ces jeux.
Nous montrerons tout d'abord que la résolution est un problème indécidable lorsque la condition de victoire est une formule de gain arbitraire.
Nous nous concentrerons ensuite sur le segment positif de ces formules, et donnerons des conditions suffisantes pour pouvoir résoudre le problème.

\newcommand\jo{joueur~0\xspace}
\newcommand\ji{joueur~1\xspace}
Afin de clarifier la présentation, nous considérons dans cette section deux joueurs, simplement désignés par les termes \jo et \ji.
Le \jo est celui qui cherche à atteindre l'objectif décrit par la formule de gain, et représente donc le nœud compromis.
Conformément à la convention adoptée dans la section précédente, ses états seront représentés sous forme de rectangles.
Le \ji quant à lui représente la coalition (l'ensemble) des autres nœuds, et ses états seront de forme circulaire.

\subsection{Indécidabilité du cas général}

Nous allons démontrer ici que le problème de victoire pour les jeux étudiés ne présente pas de solution algorithmique si la condition de victoire ne peut pas être spécifiée par une formule de gain.
Le théorème établi est le suivant:
\begin{theorem}
Le problème de victoire, ainsi que le problème de crédit initial, sont indécidables pour des objectifs définis par une formule de gain comportant quatre composantes relatives à l'énergie et une composante relative au gain.
\end{theorem}

La preuve de ce théorème consiste à encoder, à l'aide d'un jeu du type étudié, le problème de terminaison à l'aide d'une machine à deux compteurs: le problème équivalent ainsi obtenu est connu comme étant indécidable~\cite{minsky67}.
Chaque compteur est représenté par deux composantes d'énergie (une pour chacun des deux joueurs), qui contiennent chacune une copie de la valeur du compteur en question.
Pour l'instruction $0$-test (présentée ci-dessous), le \jo peut prétendre que son compteur est nul, ou bien qu'il ne l'est pas; le second joueur peut vérifier si cette affirmation est valide ou non.
Si la machine atteint son état d'arrêt, une composante de gain est incrémentée, et tous les autres composantes sont réinitialisées à $0$.
De cette manière, si la machine s'arrête, le \jo a une stratégie gagnante lui permettant d'obtenir un gain strictement positif.
Autrement, le gain demeure nul.

On définit plus précisément une machine à deux compteurs comme une liste d'instructions étiquetées, qui peuvent être:
\begin{itemize}
    \item \textbf{increment:} incrémenter le compteur $c$ (respectivement $d$) et aller à l'étiquette~$\ell$
    \item \textbf{0-test:} si $c=0$ (respectivement $d=0$) alors aller à l'étiquette~$\ell_1$, sinon décrémenter $c$ (respectivement $d$) et aller à l'étiquette~$\ell_2$
    \item \textbf{halting:} \emph{halt}
\end{itemize}
Au départ, les deux compteurs sont initialisés à $0$.

À présent, étant donné une machine $\machine$, nous construisons une arène $\G_\machine$ basée sur des modules « élémentaires » pour chaque type d'instructions (celui du compteur $c$ sera symétrique à celui du compteur $d$).
L'arène comporte donc 5 composantes $c$,$c'$,$d$,$d'$,$p$, où seule $p$ concerne le gain, les autres étant attachées à des valeurs énergétiques.
Les composantes $c$ et $c'$ (respectivement $d$ et $d'$) sont supposées toujours conserver la même valeur, excepté pour l'instruction $0$-test.
Au lancement du jeu toutes les composantes ont pour valeur\footnote{Pour obtenir une simulation plus réaliste, il est possible d'assigner aux composantes la valeur initiale $1$, et de considérer $0$ comme valeur de défaite. Nous choisissons ici d'autoriser un niveau d'énergie nul et considérons le jeu comme « perdu » pour des valeurs strictement négative, et ce afin de rendre plus clair le lien entre les valeurs des compteurs et les niveaux d'énergie.} $0$.

Le but du \jo est d'obtenir un gain strictement positif, tout en simulant fidèlement la machine.
Il faut entendre par cette expression que les valeurs des composantes $c$ et $d$ doivent demeurer positives.
Les composantes $c'$ et $d'$ permettent de s'assurer que le \ji ne pourra prétendre à tort que le \jo a triché.
Si le cas devait se produire, les valeurs de ces composantes seraient strictement négatives.
À présent la condition de victoire s'exprime comme la satisfaction de la formule de gain suivante:
\[(c\geq0 \wedge d\geq0 \wedge p>0) \vee (c'<0 \wedge c\geq0) \vee (d'<0 \wedge d\geq0)\]

Chaque instruction étiquetée a un état dans l'arène appartenant au \jo, avec la même étiquette (d'autres états seront rajoutés par la suite).
Le cas de l'incrément est trivial: si l'instruction $\ell$ est « incrémenter $c$ puis aller à l'étiquette~$\ell'$ », alors il y a une arête partant de $\ell$ et joignant $\ell'$ avec les poids $(1,1,0,0,0)$.
Il n'y a pas d'autre arête partant de $\ell$, le joueur n'a donc pas d'autre choix.

L'instruction $0$-test est plus délicate, car le \jo est susceptible de tricher en empruntant la mauvaise branche de l'instruction conditionnelle.
De manière formelle, on suppose que $\ell$ est « si $c=0$ alors aller à l'étiquette~$\ell_1$, sinon décrémenter $c$ et aller à l'étiquette~$\ell_2$ ».
Il y a alors deux arêtes sortant de l'état $\ell$: l'une correspondant à l'annonce $c=0$, l'autre à l'annonce $c>0$, comme indiqué sur la \figref{tj:fig:zerotest}.
L'arête portant l'affirmation $c=0$ atteint un état possédé par le \ji, qui peut soit accepter l'affirmation (et aller dans ce cas à $\ell_1$), soit la rejeter.
Le rejet de cette affirmation implique de décrémenter $c'$ (mais non $c$) et de se rendre sur un état \emph{stop}: cet état possède une unique arête sortante, qui boucle sur lui-même avec les poids $(0,0,0,0,0)$, signifiant que la simulation s'est arrêtée.
Si l'affirmation est rejetée à tort, on obtient $c'<0$ tandis que $c=0$, puisque les valeurs de $c$ et $c'$ étaient égales.
Si l'affirmation a été rejetée à raison, alors le gain est nul.

\begin{figure}[ht]
\centering
\begin{tikzpicture}[auto,thick,>=stealth,xscale=1.05]
\tikzstyle{stateComp}=[state, shape=rectangle]
\tikzstyle{stateNorm}=[state,inner sep=0pt]
\tikzstyle{mini}=[font=\small]

\node[stateComp] (l0) at (0,0) {$\ell$};
\node[stateNorm] (c0) at (3,0) {`$c=0$'};
\node[stateComp] (l1) at (6,0) {$\ell_1$};
\node[stateComp] (stop1) at (6,-2) {\emph{stop}};
\node[stateNorm] (cpos) at (0,-2) {`$c>0$'};
\node[stateComp] (l2) at (0,-4) {$\ell_2$};
\node[stateComp] (stop2) at (3,-4) {\emph{stop$'$}};

\draw[->] (l0) edge (c0);
\draw[->] (c0) edge (l1);
\draw[->] (c0) edge[bend right] node[mini] {$(0,-1,0,0,0)$} (stop1);

\draw[->] (l0) edge node[mini] {$(-1,-1,0,0,0)$} (cpos);
\draw[->] (cpos) edge (l2);
\draw[->] (cpos) edge (stop2);

\draw[->] (stop1) edge [loop below] (stop1);
\draw[->] (stop2) edge [loop right] node [mini] {$(0,0,0,0,1)$} (stop2);

\end{tikzpicture}
\caption[Module d'encodage de l'instruction $0$-test sous forme de jeu.]{Module d'encodage de l'instruction $0$-test sous forme de jeu: « si $c=0$ alors aller à l'étiquette~$\ell_1$, sinon décrémenter $c$ et aller à l'étiquette~$\ell_2$ ». Les états sous forme de carrés appartiennent au \jo, les cercles représentent les états du \ji. Il est convenu qu'en l'absence d'indication de poids, les arêtes comportent les poids~$(0,0,0,0,0)$.}%
\label{tj:fig:zerotest}
\end{figure}

De même, l'affirmation $c>0$ est représentée par une arête qui décrémente à la fois $c$ et $c'$ (donc de poids $(-1,-1,0,0,0)$), et atteint l'état du \ji.
Ce dernier peut soit poursuivre la simulation, soit se rendre sur un état \emph{stop$'$}.
Cet état possède une unique arête qui boucle sur lui-même avec les poids $(0,0,0,0,1)$, ce qui signifie que la simulations est arrêtée mais que le gain vaut $1$.
Si le \jo a triché, alors $c<0$ et la simulation n'a pas besoin d'être menée plus avant.
S'il s'est comporté de façon loyale, alors $c>0$ et $c'>0$, et $p>1$.

Enfin, lorsqu'il atteint l'état \emph{stop}, le \jo décrémente à la fois $c$ et $c'$ autant de fois qu'il le souhaite, puis se rend sur un état de vérification (\emph{check}).
L'état \emph{check} appartient au \ji, et agit de la même façon que pour le $0$-test dans le cas où le \jo affirme que $c=0$.
On procède de façon identique pour $d$.
Enfin, une arête retourne depuis l'état \emph{check} jusqu'à l'état initial et rapporte une récompense à la composante de gain~$p$: son poids est $(0,0,0,0,1)$.
Ce module est représenté sur la \figref{tj:fig:halt}.

\begin{figure}[ht]
\centering
\begin{tikzpicture}[auto, thick,>=stealth]
\tikzstyle{stateComp}=[state, shape=rectangle]
\tikzstyle{stateNorm}=[state,inner sep=0pt]
\tikzstyle{mini}=[font=\small]

\node[stateComp] (h) at (0,0) {\emph{halt}};
\node[stateNorm] (z) at (3,0) {\emph{check}};
\node[stateComp] (stop) at (3,-1.5) {\emph{stop}};
\node[stateComp] (l0) at (6,0) {$\ell_0$};

\draw[->] (h) edge[loop above] node[mini] {$(-1,-1,0,0,0)$} (h);
\draw[->] (h) edge[loop below] node[mini] {$(0,0,-1,-1,0)$} (h);
\draw[->] (h) edge (z);

\draw[->] (z) edge[bend right] node[mini,swap,pos=0.55] {$(0,-1,0,0,0)$} (stop);
\draw[->] (z) edge[bend left] node[mini,pos=0.55] {$(0,0,0,-1,0)$} (stop);
\draw[->] (z) edge node[mini] {$(0,0,0,0,1)$} (l0);

\draw[->] (stop) edge [loop right] (stop);

\end{tikzpicture}
\caption[Module d'encodage des instructions d'arrêt sous forme de jeu.]{Module d'encodage des instructions d'arrêt sous forme de jeu. Les états sous forme de carrés appartiennent au \jo, les cercles représentent les états du \ji.}%
\label{tj:fig:halt}
\end{figure}

Supposons à présent que \machine s'arrête.
Considérons la stratégie du \jo qui consiste à jouer honnêtement, \cad à annoncer les valeurs correctes du compteur (et à décrémenter les composantes d'énergie, de sorte qu'elles atteignent exactement $0$).
Alors si le \ji ne lance aucune accusation de tricherie, les compteurs $c$ et $d$ restent tous deux positifs, comme pour \machine.
Supposons de plus que \machine a terminé son exécution en $k$ étape, et dénotons par $c_k$ et $d_k$ les valeurs respectives de $c$ et $d$ lorsque l'on atteint les instructions d'arrêt.
Dans ce cas l'exécution de la simulation sur la machine correspond au plus à $2k$ étapes du jeu (à cause des affirmations qui doivent être acceptées), et le jeu nécessite $c_k+d_k+2$ étapes depuis l'état \emph{halt} pour atteindre à nouveau l'état initial: il s'agit du nombre d'étapes requises pour décrémenter chaque compteur et pour traverser le module de la \figref{tj:fig:halt}.
En conséquence la valeur minimale du gain moyen est de $\frac1{2k+c_k+d_k+2}>0$.

Si le \ji a rejeté l'une des affirmations du \jo:
\begin{itemize}
\item si $c=c'=0$, mais que le \ji a décrémenté $c'$ pour contester l'annonce, alors le jeu « s'arrête », mais la condition~$c'<0 \wedge c\geq0$ est satisfaite
\item si $c=c'\geq0$ après le décrément mais que le jeu a été « arrêté », le gain vaut $1$ tandis que les deux composantes $c$ et $d$ sont supérieures à $0$. Dans ce cas la condition~$c\geq0 \wedge d\geq0 \wedge p>0$ est satisfaite.
\end{itemize}

Au final, on retient que la stratégie de simulation « loyale » est gagnante.

\bigskip

Supposons maintenant que \machine ne s'arrête pas: la simulation « loyale » retourne une valeur de gain de $0$ si le \ji ne porte aucune accusation à tort (l'état d'arrêt \emph{halt} n'est jamais atteint, et si le \ji ne réfute aucune annonce, l'état \emph{stop$'$} n'est pas non plus atteint.)
Dans le cas où le \jo « ment » lors de ses annonces, il suffit au \ji de détecter cette erreur pour que l'on obtienne soit $c<0$, soit une valeur de gain définitivement nulle.

\bigskip

Cette construction peut être adaptée au problème du crédit initial: il suffit seulement de rajouter, en amont de l'état initial, un module similaire au module \emph{halt} dans le sens où il doit permettre à tous les niveaux d'énergie d'atteindre $0$.
Une fois l'état « initial » (à l'origine) atteint, le crédit initial devient caduque, et le \jo gagne si et seulement si \machine s'arrête.

\subsection{Le fragment positif}

Revenons à présent sur le problème du crédit initial, dont le jeu est plus « simple » à remporter pour le nœud compromis que le jeu du problème de victoire correspondant.
De plus il est courant, lorsque l'on combine des stratégies, qu'un crédit initial nécessaire à la victoire soit augmenté; en d'autres termes, les stratégies concernant le problème de victoire ne sont souvent pas assez robustes.
Du point de vue du modèle employé, résoudre le problème du crédit initial permet d'obtenir plus d'informations: si une stratégie et un crédit sont découverts, ils fournissent une valeur concrète à laquelle l'énergie doit être initialisée.

\bigskip

Nous démontrons dans cette section que les stratégies gagnantes pour les objectifs définis par des littéraux peuvent être combinés en une stratégie gagnante pour l'objectif global.

Rappelons avant tout que le cas d'un littéral a été étudié en détail, pour des jeux relatifs soit à de l'énergie, soit à des gains moyen.
Ces jeux ont une solution simple, dans le sens où:
\begin{itemize}
    \item l'un des joueurs a une stratégie gagnante;
    \item si une stratégie gagnante existe, alors il en existe une qui repose sur une mémoire finie;
    \item déterminer quel sera le joueur vainqueur peur être réalisé en $\NP\cap \coNP$~\cite{zwick96}.
\end{itemize}
De plus, il a été prouvé~\cite{velner12a} qu'une mémoire finie est suffisante pour gagner sur une conjonction de contraintes sur l'énergie.
Le cas des conjonctions de contraintes sur le gain a lui aussi fait l'objet d'études dans~\cite{velner12a}, où les stratégies sans mémoire pour chaque condition sur le gain sont combinées en stratégies à mémoire infinie pour l'objectif global.
Par exemple, lorsque le gain moyen des défini par la limite supérieur du gain, chaque stratégie peut être jouée au cours de phases de durée croissante jusqu'à atteindre (ou à s'approcher aussi près que nécessaire de) la valeur désirée.

Par conséquent nous allons nous concentrer ici sur l'association d'objectifs portant à la fois sur l'énergie et sur le gain moyen.
Il est bon de noter avant tout que si l'objectif du nœud compromis est une conjonction de littéraux, et que l'un deux ne peut être réalisé, il est évident que le jeu ne peut être remporté.

S'il existe des stratégies pour chacun des sous-objectifs, il peut être possible de combiner des stratégies gagnantes à mémoire finie pour chacun des littéraux en une unique stratégie gagnante, nécessitant potentiellement une mémoire infinie.
Nous allons fournir des conditions suffisantes pour obtenir une telle stratégie globale; la recherche algorithmique de la stratégie en question est un problème non résolu.

\subsubsection{Attracteurs}

Dans les jeux à deux joueurs, il est courant de faire appel à la notion d'\emph{attracteurs} d'un ensemble $Q$ pour désigner les états depuis lesquels un joueur peut forcer le jeu à se déplacer dans $Q$.

\begin{definition}
Les \emph{attracteurs en une-étape} d'un ensemble d'états $Q$ pour les joueurs~0 et~1 sont définis ainsi:
\begin{eqnarray*}
1\!\attractor{0}(Q) &=& \left\{q \in V_0 \mmid \exists (q,q') \in E \textrm{ s.t. } q' \in Q \right\}
\\&&\quad
\cup \;\left\{q \in V_1 \mmid \forall (q,q') \in E, q' \in Q \right\}
\end{eqnarray*}
\begin{eqnarray*}
1\!\attractor{1}(Q) &=& \left\{q \in V_0 \mmid \forall (q,q') \in E, q' \in Q \right\}
\\&&\quad
\cup \;\left\{q \in V_1 \mmid \exists (q,q') \in E \textrm{ s.t. } q' \in Q \right\}
\end{eqnarray*}
Les \emph{attracteurs} pour le \jo (respectivement pour le \ji) d'un ensemble $Q$ d'états sont les points fixes des attracteurs en une-étape, en partant de $Q$: pour $i \in \{0,1\}$, \[\attractor{i}(Q) = \bigcup_{j \in \N} \left(1\!\attractor{i}\right)^j(Q)\]
\end{definition}
L'attracteur pour le joueur~$i$ est donc l'ensemble des états depuis lesquels ce joueur est en mesure de s'assurer que le jeu atteindra $Q$.
On notera que pour tout état de $(1\!\attractor{i})^j(Q)$, le joueur~$i$ a une stratégie sans mémoire lui permettant d'atteindre $Q$ en au plus $j$ étapes.
Puisque le point fixe est atteint en $|V|$ itérations au plus, $Q$ peut être atteint avec un maximum de $|V|$ étapes depuis n'importe quel état de $\attractor{i}(Q)$.
On notera aussi que cette borne entraîne la possibilité de calculer les attracteurs en un temps polynomial.

\begin{lemma}
Depuis n'importe quel état de $\attractor{i}(Q)$, le joueur~$i$ possède une stratégie sans mémoire qui l'assure d'atteindre $Q$ en un maximum de $|V|$ étapes.
\end{lemma}

Une propriété des attracteurs dans les jeux est qu'ils peuvent être retirés sans danger du jeu, tout en laissant la structure du graphe restant toujours associée à un jeu (\cad sans état final):
\begin{lemma}\label{tj:lem:removeattr}
Soit $\G = \langle V_0, V_1, E\rangle$ le graphe d'un jeu (\cad tel que tout état de $V$ a une arête sortante allant dans $E$).
Soit un joueur $j \in \{0,1\}$.
Soit $Q \subseteq V$.
Considérons le graphe $\G' = (V_0', V_1', E \cap (V' \times V'))$ with $V_i' = V_i \setminus \attractor{j}(Q)$ pour $i \in \{0,1\}$.
Alors tout état de $V'$ a une arête sortante allant dans $E \cap (V' \times V')$, autrement dit $\G'$ est aussi un graphe de jeu.
\end{lemma}

\begin{proof}
Supposons par contradiction que ce ne soit pas le cas, \cad qu'il existe $q \in V'$ tel que $q$ n'a aucune arête sortante.
Comme $q$ avait une arête sortante dans le graphe de jeu $E$, cela signifie que tous les états successeurs de $q$ appartiennent à $\attractor{j}(Q)$.
Par définition d'un attracteur, on a alors $q \in \attractor{j}(Q)$, et $q \notin V'$.
\end{proof}

\subsubsection{Conjonction d'un objectif de gain et d'un objectif d'énergie}

Dans ce premier exemple simple, nous étudions les objectifs, pour le \jo, de la forme $p_e \geq c_e \wedge p_v \geq c_v$, où $p_e$ et $p_v$ sont le niveau d'énergie et la valeur du gain moyen accumulé par le \jo, et avec $c_e,c_v \in \N$.
De tels objectifs se traduisent par le besoin d'atteindre une certaine valeur de gain tandis que le niveau d'énergie demeure supérieur à une limite donnée.
Un comportement cupide est une illustration simple d'un objectif de ce type: le nœud compromis cherche à rester « en vie » ($p_e \geq 1$) tout en émettant au moins un message toutes les $6$ étapes ($p_v \geq \frac1{6}$, mais comme nous l'avons remarqué plus haut, il est possible d'obtenir un seuil à valeur entière en multipliant tous les poids de la composante par $6$).

Tout d'abord, nous pouvons clairement établir que depuis un état à partir duquel au moins un des objectifs ne peut être rempli, le \jo ne peut pas gagner.
De plus, si le \ji peut forcer le \jo à atteindre l'un de ces états, alors l'objectif du \jo ne sera pas rempli.
De là nous pouvons utiliser la notion classique d'\emph{attracteurs} dont nous avons rappelé la définition.
Nous notons $L_e$ les états où le \jo perd pour $p_e \geq c_e$ (\cad où le \ji possède une stratégie pour l'empêcher de gagner), et $L_v$ les états pour lesquels le \jo perd pour $p_v \geq c_v$.
Le \ji peut évidemment empêcher le \jo d'atteindre son objectif $p_e \geq c_e \wedge p_v \geq c_v$ depuis tout état de $\attractor{g}(L_e \cup L_v)$.
Par conséquent toute stratégie gagnante pour le \jo doit rester dans l'ensemble $\G \setminus\attractor{1}(L_e \cup L_v)$.
Par ailleurs, une stratégie gagnante qui reste dans $\G \setminus\attractor{1}(L_e \cup L_v)$ est aussi une stratégie gagnante dans $\G$ puisque le \ji ne peut pas forcer le jeu à se déplacer dans $\attractor{1}(L_e \cup L_v)$ (par définition des attracteurs).

Ainsi il devient possible de retirer, de manière récursive, des états de $\G$ jusqu'à ce que le \jo gagne pour chacun de ses objectifs depuis tous les états restants.
Si, en revanche, le graphe de jeu devient vide à un moment donné, cela signifie que le \jo ne peut pas gagner pour les deux objectifs depuis quelque état que ce soit du graphe d'origine.

Supposons à présent que le \jo dispose des stratégies gagnantes $\lambda_e$, $\lambda_v$ pour les objectifs respectifs $p_e \geq 1$ et $p_v \geq \frac1{15}$, et que ces stratégies sont gagnantes depuis tous les états.
Ces stratégies sont supposées être sans mémoire, ce sont donc des fonctions de $V_c$ dans $V$.

Considérons le jeu à un joueur $\G_e$, obtenu quand le \jo joue $\lambda_e$: chaque arête entrante dans un état $v \in V_c$ va à la place à $\lambda_e(v)$, et les poids sont cumulés: $v_0 \xrightarrow{w_1} v \xrightarrow{w_2} \lambda_e(v)$ est remplacé par $v_0 \xrightarrow{w_1+w_2} \lambda_e(v)$.
De façon similaire, soit $\G_v$ le jeu à un joueur obtenu en jouant $\lambda_v$.

Soit $\alpha$ la valeur la plus basse pouvant être obtenue pour la composante $k_v$ sur un cycle simple sur $\G_e$, et soit de même $\beta$ la valeur la plus basse pouvant être obtenue pour $k_e$ lors d'un cycle sur $\G_v$.
Plus concrètement, $\alpha$ représente la pire valeur de gain que le joueur peut obtenir lorsqu'il joue selon la stratégie qui l'assure de conserver le niveau d'énergie requis, tandis que $\beta$ est la pire valeur en énergie qui puisse être atteinte en jouant la stratégie qui assure le gain requis.
Il est à noter que si $\alpha \geq c_v$, alors $\lambda_e$ est aussi une stratégie gagnante pour l'objectif $p_v \geq c_v$, et constitue donc une stratégie gagnante pour l'objectif global.
De même si $\beta > 0$, alors $\lambda_v$ vérifie l'objectif $p_e \geq c_e$ pourvu que le crédit initial soit adapté à la somme minimale des poids des arêtes empruntées au cours d'un cycle:
\[\textrm{crédit initial} = 1+c+\min_{\substack{\rho \textrm{ préfixe de } \mathcal{C}\\
\mathcal{C}\textrm{ cycle dans } \G_v}} w_e(\rho)\]

\medskip

Si la condition suffisante que nous venons de présenter n'est pas remplie, nous n'avons pas, à ce jour, de solution pour résoudre ces jeux dans un contexte général.
Des stratégies gagnantes pour chaque composante pourraient en effet se révéler incompatibles entre elles.
Prenons, pour illustrer, l'exemple du jeu à un seul joueur présenté en \figref{tj:fig:infmemoryneeded}.
Dans cet exemple, $q_0$ agit comme un état de recharge (en énergie) tandis que $q_1$ est un état actif qui produit un effet utile récompensé par une valeur de gain.
On constate que recharger la batterie est bien plus lent que de consommer l'énergie, puisqu'il faut 42 « unités d'énergie\footnote{Ce peut être, par exemple, une joule, ce qui signifierait que l'étape active consommerait avec une puissance de 42~W, tandis que la puissance de la recharge serait de 1~W. La valeur 42 a été choisie arbitrairement pour cet exemple.} » par étape active.

Il est possible de maintenir un niveau d'énergie constamment positif (pour la première composante) en restant dans $q_0$ (où en y allant si l'on commence en $q_1$).
Il est aussi possible d'atteindre un gain moyen de $1$ en demeurant sur $q_1$ (ou en s'y rendant si l'on démarre sur $q_0$, car le poids de l'unique arête empruntée est négligeable sur une longue exécution).
Cependant, il n'est pas possible de conserver un gain moyen de $1$ tout en maintenant un niveau d'énergie positif, puisqu'une fois le crédit initial écoulé, 42~étapes de recharge doivent impérativement être effectuées avant de réaliser toute action susceptible de rapporter un gain.

\begin{figure}[ht]
\centering
\begin{tikzpicture}[auto, thick,>=stealth]
\tikzstyle{stateComp}=[state, shape=rectangle]

\node[stateComp] (q0) at (0,0) {$q_0$};
\node[stateComp] (q1) at (3,0) {$q_1$};

\path[->] (q0) edge[loop left] node {$+1,0$} (q0);
\path[->] (q0) edge[bend left=15] node {$0,0$} (q1);
\path[->] (q1) edge[loop right] node {$-42,+1$} (q1);
\path[->] (q1) edge[bend left=15] node {$0,0$} (q0);
\end{tikzpicture}
\caption[Un exemple de jeu simple nécessitant une mémoire infinie.]{Un exemple de jeu simple nécessitant une mémoire infinie. La première composante est un niveau d'énergie, la seconde est une valeur de gain.}%
\label{tj:fig:infmemoryneeded}
\end{figure}

\subsubsection{Avec mémoire limitée}

Nous considérons que les \wsns sont fortement limités en ressources disponibles, et ne peuvent donc implémenter que des stratégies à mémoire finie.
Dans ce cas, limiter \apriori la quantité de mémoire qui peut être utilisée par le joueur fournit une solution pour résoudre le problème du crédit initial pour des jeux ayant une condition de victoire sur le fragment positif.

Une stratégie à mémoire finie est une stratégie qui peut être implémentée par une machine de Mealy finie et déterministe: état donné l'état actuel de la machine et du jeu, la machine fournit l'arête à emprunter et de là l'état suivant de la machine.
La taille de machine de Mealy est la taille de la mémoire disponible.

Par exemple, une stratégie à mémoire finie pour le jeu de la \figref{tj:fig:infmemoryneeded}, qui boucle 42~fois sur $q_0$ puis se rend sur $q_1$, boucle une fois et enfin retourne sur $q_0$ pour recommencer le cycle, est représentée sur la machine de la \figref{tj:fig:memory42}.
Cette machine possède 46~états, puisqu'elle nécessite de compter (et donc garder en mémoire) le nombre de fois où l'on a bouclé sur $q_0$ pour accumuler de l'énergie.
Si l'on devait démarrer en $q_1$, la machine se rendrait tout d'abord en $q_0$ avant d'appliquer la stratégie que nous venons de décrire.
La machine doit être complète au niveau des entrées possibles, aussi faut-il autoriser $q_1$ à survenir depuis n'importe quel état mémoire (dans notre cas elle retourne à l'état mémoire initial, tandis que le jeu retourne en $q_0$).

\begin{figure}[ht]
\centering
\begin{tikzpicture}[auto, thick,>=stealth]
\useasboundingbox (-1.25,1.45) rectangle (7.8,-3.15);
\node[state, initial,initial text=] (m0) at (0,0) {$m_0$};
\node[state] (m1) at (2,0) {$m_1$};
\node (dots) at (3.5,0) {\dots};
\node[state] (m42) at (5,0) {$m_{42}$};
\node[state] (m43) at (7,0) {$m_{43}$};
\node[state] (m44) at (7,-2) {$m_{44}$};
\node[state] (m45) at (5,-2) {$m_{45}$};

\draw[->] (m0) edge[loop above] node {$q_1 | q_0$} (m0);
\draw[->] (m0) edge node {$q_0 | q_0$} (m1);
\draw[->] (m1) edge node {$q_0 | q_0$} (dots);
\draw[->] (m42) edge node {$q_0 | q_0$} (m43);
\draw[->] (m43) edge node {$q_0 | q_1$} (m44);
\draw[->] (m44) edge node {$q_1 | q_1$} (m45);
\draw[->] (m45) edge[bend left] node[swap,pos=0.15] {$q_1 | q_0$} (m0);

\draw[->] (m1) edge[bend left=15] node[pos=0.15] {$q_1 | q_0$} (m0);
\draw[->] (m42) edge[bend left=25] node[,pos=0.15] {$q_1 | q_0$} (m0);
\draw[->] (m43) edge[bend left=45] node[swap,pos=0.33] {$q_1 | q_0$} (m0);
\draw[->] (m44) edge[bend left=60, in =60] node[pos=0.75] {$q_0 | q_0$} (m0);
\draw[->] (m45) edge[bend left=60] node[pos=0.1] {$q_0 | q_0$} (m0);
\end{tikzpicture}
\caption[Une machine de Mealy représentant une stratégie à mémoire finie.]{Une machine de Mealy représentant une stratégie à mémoire finie (46~états). L'extrémité sortante d'une arête représente l'état actuel du jeu, l'extrémité sortante est l'état suivant retenu.}%
\label{tj:fig:memory42}
\end{figure}

\begin{remark}
Les stratégies pour une quantité finie donnée de mémoire peuvent ne pas être optimales.
Considérons par exemple le jeu de la \figref{tj:fig:infmemoryneeded} avec pour objectif le maintien du niveau d'énergie au-dessus de $0$ et d'obtenir un gain moyen supérieur ou égal à $\frac1{43}$.

Une stratégie à mémoire infinie pourrait remporter la victoire sur ce jeu.
Elle serait découpée en phases qui se dérouleraient de la manière suivante: à la $k$\textsuperscript{ième} phase, il faudrait boucler $42k$~fois sur $q_0$, puis se rendre en $q_1$; il faudrait alors boucler $k$~fois avant de retourner sur $q_0$.
Cela permettrait de faire en sorte que les poids des transitions entre $q_0$ et $q_1$ soient négligeables, et d'obtenir une limite, pour le gain moyen, de $\frac1{43}$, puisque 43~étapes seraient nécessaires pour incrémenter le compteur de gain d'une unité.
De plus, à chaque phase, le niveau d'énergie retombe à sa valeur initiale, puis ne prend que des valeurs supérieures à celle-ci.

En revanche, si seulement $m$ états de mémoire sont autorisés, la meilleure valeur de gain moyen que l'on peut espérer obtenir est de $\frac{m}{43m+2}$ (la stratégie correspondante consiste à répéter la phase $m$).
Ainsi, avec une mémoire finie, non seulement le gain moyen optimal ne peut pas être atteint, mais on constate de plus que l'allocation de davantage de mémoire permet d'atteindre une meilleure valeur de gain moyen.
\end{remark}

Résoudre le jeu en supposant que le \jo a une mémoire finie limitée à un nombre $k$ d'unités fourni en entrée revient à deviner sa stratégie sous forme de machine de Mealy, ce qui constitue un objet de taille exponentielle si $k$ est fournie sous forme binaire.
La machine est alors synchronisée avec le jeu, et retourne un second jeu à un seul joueur, à faire jouer par le \ji.
Dans ce second jeu, seules les stratégies sans mémoires doivent êtres prises en compte.

En effet, tout chemin infini qui ne satisferait pas $p_e \geq c_e \wedge p_v \geq c_v$ vérifierait, à un moment ou l'autre, soit $p_e < c_e$, soit $p_v < c_v$ (en considérant la limite pour le gain moyen de $p_v$).
Dans les deux cas cela revient à trouver un chemin en « lasso » dans le graphe, ce qui peut être deviné.

En ce qui concerne la complexité, la procédure que nous venons de décrire est dans $\NEXPSPACE$ (qui est équivalent à $\EXPSPACE$~\cite[Chap.~20]{papadimitriou94}), même si la borne n'est pas atteinte.
